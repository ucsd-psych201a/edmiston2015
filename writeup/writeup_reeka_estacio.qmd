---
title: "Replication of Experiment 1A by Edmiston & Lupyan (2015, Cognition)"
author: "Reeka Estacio"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

This is a replication study of Experiment 1A of Edmiston & Lupyan (2015). The original study examines the difference in which verbal labels and environmental sounds activate categories in the mind. I believe this study has interesting insights into how human language is unique compared to other forms of informative inputs and theorizes how broad, verbal labels contributes to the efficiency in which humans process language. These findings may have potential implications in how natural language processing technologies, like large language models and speech recognition software, can be built to model more naturalistic language learning.

The stimuli presented in experiment 1A of this study involve six categories, such as *bird*, *dog*, and *phone*. For each category, two environmental sound cues were obtained, each corresponding to a more specific exemplar of that category. For instance, the *guitar* category includes the sound of an acoustic guitar strum and the sound of an electric guitar strum. Two images were obtained for each exemplar respectively for the task (e.g. two images of an acoustic guitar and two images of an electric guitar). Finally, verbal labels, spoken from both female and male speakers, were obtained for each category. The procedure is an image matching verification task. Participants are randomly presented with an auditory cue (either the verbal label or an environmental sound) and are tasked to respond "Yes" on a gaming controller if the image matches the auditory cue, or "No" if it does not. In total, participants completed 6 practice trials and 384 test trials. Verification speed was recorded.

## Methods

### Power Analysis

Since the original study used a linear mixed regression analysis, it is difficult to perform a power analysis. For this reason, we have decided to use the 2.5x sample size heuristic to ensure that our study has adequate power.

### Planned Sample

In the original study, the participants for Experiment 1A were described as the following: 

"43 University of Wisconsin–Madison undergraduates participated in Experiment 1A in exchange for course credit."

As specified in our power analysis, we plan to have 2.5x participants as the original sample (n=108). These participants will be recruited and compensated through on Prolific.

### Materials

From the original study:

"The auditory cues comprised basic-level category labels and environmental sounds for six categories: bird, dog, drum, guitar, motorcycle, and phone. For each category, we obtained two distinct environmental sound cues, e.g., <classical guitar strum>, <electric guitar strum>, and two separate images for each subordinate category, e.g., two electric guitars for <electric guitar strum>, two acoustic guitars for <electric guitar strum>. To control for cue variability, we also used two versions of each spoken category label: one pronounced by a female speaker, one by a male speaker. All auditory cues were equated in duration (600 ms.) and normalized in volume. The images were color photographs (four images per category). The materials, obtained from online repositories, are available for download at http://sapir.psych.wisc.edu/stimuli/ MotivatedCuesExp1A-1B.zip."

We will use the same materials for the replication study, as all materials were provided by the original authors.  


### Procedure	

From the original study:

"On each trial participants heard a cue and saw a picture. We instructed participants to decide as quickly and accurately as possible if the picture they saw came from the same basic-level category as the word or sound they heard Participants were tested in individual rooms sitting approximately 2400 from a monitor such that images subtended 10  10°. Trials began with a 250 ms. fixation cross followed immediately by the auditory cue, delivered via headphones. The target image appeared centrally 1 s after the off- set of the auditory cue and remained visible until a response was made. Each participant completed 6 practice and 384 test trials. If the picture matched the auditory cue (50% of trials) participants were instructed to respond ‘Yes’ on a gaming controller (e.g., <cell- phone ring> or ‘‘phone’’ followed by a picture of any phone). Otherwise, they were to press ‘No’ (e.g., <cellphone ring> or ‘‘phone’’ followed by a dog). All factors (cue type, congruence) var- ied randomly within subjects. Auditory feedback (buzz or bleep) was given after each trial."

We aim to follow the original procedure of Experiment 1A as precisely as possible. However, instead of running the trials in-person, the experiment will be conducted online using jsPsych. For this reason, the task will be slightly different such that participants will respond to trials using their keyboard keys instead of a gaming controller. We will also encourage participants to wear headphones, be in a quiet area for the auditory cues during the experiment, and provide an initial audio check to ensure that participants have access to all stimuli presented throughout the experiment.

### Analysis Plan

From the original study:

"All participants performed very accurately on all items (M = 97%). Response times (RTs) shorter than 250 ms. or longer than 1500 ms. were removed (292 trials removed, 1.77% of total).

We fit RTs for correct responses on matching trials (‘Yes’ responses) with linear mixed regression using maximum likelihood estimation (Bates, Maechler, Bolker, & Walker, 2013), including random intercepts and random slopes for within-subject factors and random intercepts for repeated items (unique trial types) following the recommendations of Barr, Levy, Scheepers, and Tily (2013). Reported below are the parameter estimates (b) and confidence intervals for each contrast of interest. Significance tests were calculated using chi-square tests that compared nested models—models with and without the factor of interest—on improvement in log-likelihood."

For our replication, we will also remove trials where response times are shorter than 250 ms or longer than 1500ms from the analysis. We will then run a similar linear mixed regression model, as was performed the original study. We will also use chi-square tests to assess significance of the results. We anticipate that a successful replication of the original study will yield similar effects. More specifically, we should find that verbal labels elicit the lowest overall reaction times, and that congruent sounds elicit lower reaction times than incongruent sounds.


**Clarify key analysis of interest here**: Linear mixed regression model, chi-square tests for significance

### Differences from Original Study

This replication will differ from the original study in terms of setting and procedure. As previously mentioned, the experiments will be conducted online using jsPsych as opposed to in-person in a lab setting. Loading/internet speed of the participants' personal devices may affect overall reaction times. Participants will also be using their keyboard to respond to trials as opposed to the gaming controller used in the original study. However, we do not anticipate that these differences will greatly affect results or ability to obtain the same effect as described in the original study.


### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.

## Design Review

In our analysis, one factor is directly manipulated: the auditory cue that was presented to participants. There are three conditions of that factor: verbal label, congruent sound, and incongruent sound.

There was one measure taken, which is reaction time (RT).

This study uses a within-participants design.

The measures were repeated; there were 384 experimental trials in the original experiment.

It would not make sense for the experiment to be changed to between-participants because the measures would not be as accurate. There will be individual differences of RTs regardless of experimental conditions.

No known steps were taken to reduce demand characteristics. 

They should have added attention checks between trials to ensure participants are attentive throughout trials. They could have also kept "No" responses. Incongruent sounds may have prompted participants to respond "No", but these are still valid responses.

The original study involved undergraduate participants, which raises generalizability issues because they are inherently a WEIRD population.

## Pilot A

For our Pilot A (with non-naive participants), we aimed to replicate the experimental paradigm described in the study. The GitHub page for our paradigm is linked below:

[Link to experimental paradigm](https://ucsd-psych201a.github.io/edmiston2015/)

We have collected pilot data from three participants. This data was imported and uploaded to the data folder in the project repository.

[Link to Pilot A data](https://github.com/ucsd-psych201a/edmiston2015/tree/main/data/pilot_a)

## Pilot B

For our Pilot B (with naive participants), we collected data from five participants on Prolific. The following "Results" section (Data Preparation and Confirmatory Analysis) is run on Pilot B data for the time-being. As predicted, the participants took an average of about 25 minutes to complete the experiment.

[Link to Pilot B data](https://github.com/ucsd-psych201a/edmiston2015/tree/main/data/pilot_b)

## Results

### Data preparation

Data preparation following the analysis plan.

The following code combines the data that has been collected from our experiment (currently Pilot B) and performs the necessary data wrangling to run through our analysis model. Similar to the original study, practice trials and "No" trials were removed. Trials where reaction times are less than 250 ms or exceed 1500 ms after stimulus presentation were also excluded. This also labels the conditions for later analysis (i.e. `congruent`, `incogruent`).
	
```{r}
### Data Preparation

#### Load Relevant Libraries and Functions
library(tidyverse)
library(readr)
library(lme4)
```

```{r}
#### Import data
## currently using pilot B data
folder_path <- "../data/pilot_b"
csv_files <- list.files(folder_path, pattern = "*.csv", full.names = TRUE)
df_list <- lapply(csv_files, read_csv)
combined_df <- bind_rows(df_list)

#### Data exclusion / filtering
#exclude 'No' trials 
combined_df <- combined_df %>%
  mutate(response = as.character(response)) %>%
  filter(response == "f")         # use "y" for pilot_a data, use "f" for pilot_b data

#exclude practice trials 
combined_df <- combined_df %>%
  filter(exp_part == "actual")

#rename "sound_subtype" to "cue"
combined_df <- combined_df %>%
  rename(cue = sound_subtype)

#create congruency column 
combined_df <- combined_df %>%
  mutate(congruency = case_when(
    cue == "label" ~ "label",
    img_subtype %in% c("song", "york", "bongo", "acoustic", "harley", "rotary") & sound_version == "A" ~ "incongruent",
    TRUE ~ "congruent"
  ))

#filter reaction time 
combined_df <- combined_df %>%
  filter(rt >250, rt <1500)

#### Prepare data for analysis - create columns etc.
combined_df <- combined_df %>%
  select(rt, ID, sound_category,cue, congruency)
```

### Confirmatory analysis

Following the confirmatory analysis of the original study, our replication will also perform a linear mixed effects regression model fit on response times to correct trials on congruent trials. The details of the analysis are specified in the "Analysis Plan" section of this writeup. Again, the current analysis is run on data collected from Pilot B.

```{r}
library(lmerTest)
library(emmeans)
library(lme4)

#shows you a comparsion between reference (congruent) and the other two values (incongruent and label)
model_full <- lmer(rt ~ congruency + (1 + congruency|ID) + (1|sound_category), data = combined_df)

summary(model_full)

#get 95% CI
confint.merMod(model_full,method="Wald")

#post-hoc test: allows you to examine relationship between incongruent and label
model_full %>% 
  emmeans(pairwise ~ congruency,
          #adjusts p values so that it is more difficult to get a significance (correction method)
          adjust = "bonferroni") %>% 
  pluck("contrasts")


#chi squared test 
model_reduced <- lmer(rt ~ (1 + congruency|ID) + (1|sound_category), data = combined_df)

anova(model_full, model_reduced)

# model for Pilot A shows us that incongruent takes longer than congruent (b = 28.7), that label is shorter than congruent (b = -15.52), and that incongruent takes longer than label (b = 44.3) 
```

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
